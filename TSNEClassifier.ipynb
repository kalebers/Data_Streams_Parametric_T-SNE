{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "from parametric_tsne import ParametricTSNE\n",
    "from river import drift\n",
    "from river import synth\n",
    "from river import ensemble, linear_model\n",
    "from river import metrics, evaluate, datasets, tree, preprocessing, base\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_river_iterator(X, y=None, classes=None):\n",
    "    if classes == None:\n",
    "        classes = [\"x\",\"y\"] + [chr(97 + i) for i in range(len(X[0])-2)]\n",
    "    if y is None:\n",
    "        y = [False for i in range(len(X))]\n",
    "    dict_list = []\n",
    "    for instance, y_pred in zip(X,y):\n",
    "        _instance = (dict(zip(classes,instance)), y_pred)\n",
    "        dict_list.append(_instance)\n",
    "    \n",
    "    return islice(dict_list,0)\n",
    "\n",
    "\n",
    "def matrix_to_dict(X):\n",
    "    classes = [\"x\",\"y\"]\n",
    "    \n",
    "    dict_list = []\n",
    "    for instance in X:\n",
    "        dict_list.append(dict(zip(classes,instance)))\n",
    "    \n",
    "    return dict_list\n",
    "\n",
    "\n",
    "def dict_to_highest_class(y):\n",
    "    highest_classes = []\n",
    "    for instance in y:\n",
    "        highest_classes.append(list({k: v for k, v in sorted(instance.items(), key=lambda item: item[1])}.keys())[-1])\n",
    "    \n",
    "    return highest_classes\n",
    "\n",
    "\n",
    "def round_probs(d):\n",
    "    for key in d.keys():\n",
    "        d[key] = round(d[key])\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSNEClassifier(base.Classifier):\n",
    "    def __init__(self, classifier, n_components=2, perplexity=30., verbose=0):\n",
    "        self.classifier = classifier\n",
    "        self.tsne = ParametricTSNE(n_components, perplexity, verbose)\n",
    "        self._x_instances = []\n",
    "        self._y_instances = []\n",
    "        \n",
    "    def fit(self, X, y=None, batch_size=100, n_iter_tsne=100):\n",
    "        if batch_size > len(X):\n",
    "            batch_size = len(X)\n",
    "            \n",
    "        self.tsne.fit(X,y,batch_size=batch_size, n_iter=n_iter_tsne)\n",
    "        X_new = self.tsne.transform(X)\n",
    "        for instance_x, instance_y in zip(X_new, y):\n",
    "            self.classifier.learn_one({'x':instance_x[0], 'y':instance_x[1]}, instance_y)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        X_new = self.tsne.transform(X)\n",
    "        X_new = matrix_to_dict(X_new)\n",
    "        if not self.classifier.predict_one:\n",
    "            return [round_probs(self.classifier.predict_proba_one(instance)) for instance in X_new]\n",
    "        \n",
    "        return [self.classifier.predict_one(instance) for instance in X_new]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_new = self.tsne.transform(X)\n",
    "        X_new = matrix_to_dict(X_new)\n",
    "        return [self.classifier.predict_proba_one(instance) for instance in X_new]\n",
    "    \n",
    "    def learn_one(self, x, y=None):\n",
    "        if len(self._x_instances) < self._batch_size:\n",
    "            self._x_instances.append(x)\n",
    "            self._y_instances.append(y)\n",
    "            return self\n",
    "        \n",
    "        result = self.fit(np.array(self._x_instances), np.array(self._y_instances))\n",
    "        self._x_instances = []\n",
    "        self._y_instances = []\n",
    "        return result\n",
    "        \n",
    "        '''\n",
    "        x_list = list(x.values())\n",
    "        x = np.asarray(x_list).reshape(1,len(x_list))\n",
    "        self.tsne.fit(x,y)\n",
    "        X_new = self.tsne.transform(x)\n",
    "        return self.classifier.learn_one({'x': X_new[0][0], 'y': X_new[0][1]}, y)\n",
    "        '''\n",
    "    \n",
    "    def predict_one(self, x, y=None):\n",
    "        x_list = list(x.values())\n",
    "        X_new = self.tsne.transform(np.asarray(x_list).reshape(1,len(x_list)))\n",
    "        X_new = matrix_to_dict(X_new)[0]\n",
    "        return self.classifier.predict_one(X_new)\n",
    "    \n",
    "    def predict_proba_one(self, x, y=None):\n",
    "        X_new = self.tsne.transform(x.values())\n",
    "        X_new = matrix_to_dict(X_new)\n",
    "        return self.classifier.predict_proba_one(X_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [ensemble.ADWINBaggingClassifier(model=linear_model.LogisticRegression(), n_models=10, seed=None),\n",
    "              ensemble.AdaBoostClassifier(model=(tree.HoeffdingTreeClassifier(split_criterion='gini', split_confidence=1e-5, grace_period=2000)), n_models=10, seed=None),\n",
    "              ensemble.AdaptiveRandomForestClassifier(n_models=10, max_features=\"sqrt\", lambda_value=6, metric=metrics.Accuracy(), disable_weighted_vote=False, drift_detector=drift.ADWIN(), warning_detector=drift.ADWIN(), grace_period=50, max_depth=None, split_criterion=\"info_gain\", split_confidence=0.01, tie_threshold=0.05, leaf_prediction=\"nba\", nb_threshold=0, nominal_attributes=None, splitter=None, max_size=32, memory_estimate_period=2000000, seed=None),\n",
    "              ensemble.BaggingClassifier(model=(preprocessing.StandardScaler() | linear_model.LogisticRegression()), n_models=10, seed=None),\n",
    "              ensemble.LeveragingBaggingClassifier(model=(preprocessing.StandardScaler() | linear_model.LogisticRegression()), n_models=10, w=6, adwin_delta=0.002, bagging_method=\"bag\", seed=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(n_features, n_cat_features, seed=None): # 50/50 pra num/cat\n",
    "    return {\n",
    "        \"Hyperplane\": synth.Hyperplane(seed=seed, n_features=n_features),\n",
    "        \"RandomRBF\": synth.RandomRBF(seed_sample=seed, n_features=n_features),\n",
    "        \"RandomRBFDrift\": synth.RandomRBFDrift(seed_sample=seed, n_features=n_features),\n",
    "        \"RandomTree\": synth.RandomTree(seed_sample=seed, n_num_features=n_features, n_cat_features=n_cat_features)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [synth.Hyperplane(seed=None, n_features=10, n_drift_features=2, mag_change=0.0, noise_percentage=0.05, sigma=0.1), \n",
    "           synth.RandomRBF(seed_model=None, seed_sample=None, n_classes=2, n_features=10, n_centroids=50),\n",
    "           synth.RandomRBFDrift(seed_model=None, seed_sample=None, n_classes=2, n_features=10, n_centroids=50, change_speed=0.0, n_drift_centroids=50),\n",
    "           synth.RandomTree(seed_tree=None, seed_sample=None, n_classes=2, n_num_features=5, n_cat_features=5, n_categories_per_feature=5, max_tree_depth=5, first_leaf_level=3, fraction_leaves_per_level=0.15)]\n",
    "\n",
    "#número de features varia entre 50,100,200,500,1000,2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers vs. Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def evaluate_tsne_classifiers_datasets(classifiers, datasets, n, m):\n",
    "    results = {}\n",
    "    for classifier in classifiers:\n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            tsne_classifier = TSNEClassifier(classifier)\n",
    "            data= np.asarray(list(dataset.take(n)))\n",
    "            dataset_x = np.asarray([np.asarray(list(a[0].values())) for a in data])\n",
    "            dataset_y = np.asarray([a[1] for a in data])\n",
    "            \n",
    "            for x, y in zip(dataset_x,dataset_y):\n",
    "                tsne_classifier.learn_one(x,y)\n",
    "            \n",
    "            pred_data = list(dataset.take(m))\n",
    "            pred_x_data = np.asarray([np.asarray(list(a[0].values())) for a in pred_data])\n",
    "            true_pred_y = np.asarray([a[1] for a in pred_data])\n",
    "            \n",
    "            metric = metrics.Accuracy()\n",
    "            y_pred = dict_to_highest_class(tsne_classifier.predict_proba(pred_x_data))\n",
    "            for yt, yp in zip(true_pred_y, y_pred):\n",
    "                metric = metric.update(yt, yp)\n",
    "            results[classifier.__class__.__name__ + \"_\" + dataset_name] = metric\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(classifier.__class__.__name__ + \"_\" + dataset_name, metric)\n",
    "    \n",
    "    return results\n",
    "            \n",
    "\n",
    "def evaluate_classifiers_datasets(classifiers, datasets, n, m):\n",
    "    results = {}\n",
    "    for classifier in classifiers:\n",
    "        for dataset_name, dataset in datasets.items():\n",
    "            data= np.asarray(list(dataset.take(n)))\n",
    "            \n",
    "            for x, y in data:\n",
    "                classifier.learn_one(x,y)\n",
    "            \n",
    "            metric = metrics.Accuracy()\n",
    "            pred_data = np.asarray(list(dataset.take(m)))\n",
    "            for x,y in pred_data:\n",
    "                y_pred = dict_to_highest_class([classifier.predict_proba_one(x)])[0]\n",
    "                metric = metric.update(y, y_pred)\n",
    "            \n",
    "            results[classifier.__class__.__name__ + \"_\" + dataset_name] = metric\n",
    "            \n",
    "            clear_output(wait=True)\n",
    "            print(classifier.__class__.__name__ + \"_\" + dataset_name, metric)\n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic datasets experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 numeric features, 5 categoric features, 1000 train, 500 test\n",
    "datasets = generate_datasets(10,5)\n",
    "\n",
    "#Parametric t-SNE results\n",
    "results_tsne_10 = evaluate_tsne_classifiers_datasets(classifiers, datasets, 1000, 500)\n",
    "results_tsne_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeveragingBaggingClassifier_RandomTree Accuracy: 41.20%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADWINBaggingClassifier_Hyperplane': Accuracy: 49.80%,\n",
       " 'ADWINBaggingClassifier_RandomRBF': Accuracy: 50.00%,\n",
       " 'ADWINBaggingClassifier_RandomRBFDrift': Accuracy: 51.00%,\n",
       " 'ADWINBaggingClassifier_RandomTree': Accuracy: 52.80%,\n",
       " 'AdaBoostClassifier_Hyperplane': Accuracy: 77.80%,\n",
       " 'AdaBoostClassifier_RandomRBF': Accuracy: 54.80%,\n",
       " 'AdaBoostClassifier_RandomRBFDrift': Accuracy: 56.40%,\n",
       " 'AdaBoostClassifier_RandomTree': Accuracy: 56.80%,\n",
       " 'AdaptiveRandomForestClassifier_Hyperplane': Accuracy: 70.20%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBF': Accuracy: 58.60%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBFDrift': Accuracy: 48.00%,\n",
       " 'AdaptiveRandomForestClassifier_RandomTree': Accuracy: 61.40%,\n",
       " 'BaggingClassifier_Hyperplane': Accuracy: 52.20%,\n",
       " 'BaggingClassifier_RandomRBF': Accuracy: 50.40%,\n",
       " 'BaggingClassifier_RandomRBFDrift': Accuracy: 54.20%,\n",
       " 'BaggingClassifier_RandomTree': Accuracy: 60.20%,\n",
       " 'LeveragingBaggingClassifier_Hyperplane': Accuracy: 68.20%,\n",
       " 'LeveragingBaggingClassifier_RandomRBF': Accuracy: 43.80%,\n",
       " 'LeveragingBaggingClassifier_RandomRBFDrift': Accuracy: 49.80%,\n",
       " 'LeveragingBaggingClassifier_RandomTree': Accuracy: 41.20%}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standard results\n",
    "results_standard_10 = evaluate_classifiers_datasets(classifiers, datasets, 1000, 500)\n",
    "results_standard_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeveragingBaggingClassifier_RandomTree Accuracy: 64.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADWINBaggingClassifier_Hyperplane': Accuracy: 55.67%,\n",
       " 'ADWINBaggingClassifier_RandomRBF': Accuracy: 50.33%,\n",
       " 'ADWINBaggingClassifier_RandomRBFDrift': Accuracy: 40.00%,\n",
       " 'ADWINBaggingClassifier_RandomTree': Accuracy: 45.67%,\n",
       " 'AdaBoostClassifier_Hyperplane': Accuracy: 52.33%,\n",
       " 'AdaBoostClassifier_RandomRBF': Accuracy: 41.33%,\n",
       " 'AdaBoostClassifier_RandomRBFDrift': Accuracy: 42.33%,\n",
       " 'AdaBoostClassifier_RandomTree': Accuracy: 65.00%,\n",
       " 'AdaptiveRandomForestClassifier_Hyperplane': Accuracy: 51.67%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBF': Accuracy: 43.67%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBFDrift': Accuracy: 43.00%,\n",
       " 'AdaptiveRandomForestClassifier_RandomTree': Accuracy: 54.67%,\n",
       " 'BaggingClassifier_Hyperplane': Accuracy: 53.33%,\n",
       " 'BaggingClassifier_RandomRBF': Accuracy: 62.00%,\n",
       " 'BaggingClassifier_RandomRBFDrift': Accuracy: 45.67%,\n",
       " 'BaggingClassifier_RandomTree': Accuracy: 78.33%,\n",
       " 'LeveragingBaggingClassifier_Hyperplane': Accuracy: 46.33%,\n",
       " 'LeveragingBaggingClassifier_RandomRBF': Accuracy: 51.67%,\n",
       " 'LeveragingBaggingClassifier_RandomRBFDrift': Accuracy: 53.67%,\n",
       " 'LeveragingBaggingClassifier_RandomTree': Accuracy: 64.67%}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#100 numeric features, 10 categoric features, 500 train, 300 test\n",
    "datasets = generate_datasets(100,10)\n",
    "\n",
    "#Parametric t-SNE results\n",
    "results_tsne_100 = evaluate_tsne_classifiers_datasets(classifiers, datasets, 500, 300)\n",
    "results_tsne_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeveragingBaggingClassifier_RandomTree Accuracy: 49.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ADWINBaggingClassifier_Hyperplane': Accuracy: 48.00%,\n",
       " 'ADWINBaggingClassifier_RandomRBF': Accuracy: 50.67%,\n",
       " 'ADWINBaggingClassifier_RandomRBFDrift': Accuracy: 58.67%,\n",
       " 'ADWINBaggingClassifier_RandomTree': Accuracy: 44.67%,\n",
       " 'AdaBoostClassifier_Hyperplane': Accuracy: 51.00%,\n",
       " 'AdaBoostClassifier_RandomRBF': Accuracy: 46.67%,\n",
       " 'AdaBoostClassifier_RandomRBFDrift': Accuracy: 52.67%,\n",
       " 'AdaBoostClassifier_RandomTree': Accuracy: 32.67%,\n",
       " 'AdaptiveRandomForestClassifier_Hyperplane': Accuracy: 50.67%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBF': Accuracy: 43.00%,\n",
       " 'AdaptiveRandomForestClassifier_RandomRBFDrift': Accuracy: 36.67%,\n",
       " 'AdaptiveRandomForestClassifier_RandomTree': Accuracy: 60.00%,\n",
       " 'BaggingClassifier_Hyperplane': Accuracy: 58.67%,\n",
       " 'BaggingClassifier_RandomRBF': Accuracy: 63.00%,\n",
       " 'BaggingClassifier_RandomRBFDrift': Accuracy: 47.33%,\n",
       " 'BaggingClassifier_RandomTree': Accuracy: 50.33%,\n",
       " 'LeveragingBaggingClassifier_Hyperplane': Accuracy: 69.00%,\n",
       " 'LeveragingBaggingClassifier_RandomRBF': Accuracy: 49.67%,\n",
       " 'LeveragingBaggingClassifier_RandomRBFDrift': Accuracy: 47.67%,\n",
       " 'LeveragingBaggingClassifier_RandomTree': Accuracy: 49.33%}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Standard results\n",
    "results_standard_100 = evaluate_classifiers_datasets(classifiers, datasets, 500, 300)\n",
    "results_standard_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:22<00:00,  4.36it/s]\n",
      "D:\\Usuario\\Anaconda3_2\\envs\\lixoLearning\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.TSNEClassifier at 0x2a13cbefa58>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne = TSNEClassifier(AdaptiveRandomForestClassifier())\n",
    "\n",
    "dataset= np.asarray(list(datasets.Phishing().take(100)))\n",
    "dataset_x = np.asarray([np.asarray(list(a[0].values())) for a in dataset])\n",
    "dataset_y = np.asarray([a[1] for a in dataset])\n",
    "\n",
    "tsne.fit(dataset_x, dataset_y,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne.predict(dataset_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple batches\n",
    "First batch: 200; Second batch: 20; Test: 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.16it/s]\n",
      "D:\\Usuario\\Anaconda3_2\\envs\\lixoLearning\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 75/75 [00:03<00:00, 22.75it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[True, True, True, False, True]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne = TSNEClassifier(ensemble.AdaptiveRandomForestClassifier())\n",
    "\n",
    "dataset= np.asarray(list(datasets.Phishing().take(200)))\n",
    "dataset_x = np.asarray([np.asarray(list(a[0].values())) for a in dataset])\n",
    "dataset_y = np.asarray([a[1] for a in dataset])\n",
    "\n",
    "tsne.fit(dataset_x, dataset_y,batch_size=20, n_iter_tsne=50)\n",
    "\n",
    "dataset= np.asarray(list(datasets.Phishing().take(20)))\n",
    "dataset_x = np.asarray([np.asarray(list(a[0].values())) for a in dataset])\n",
    "dataset_y = np.asarray([a[1] for a in dataset])\n",
    "\n",
    "tsne.fit(dataset_x, dataset_y,batch_size=20, n_iter_tsne=75)\n",
    "\n",
    "\n",
    "dataset= np.asarray(list(datasets.Phishing().take(5)))\n",
    "dataset_x = np.asarray([np.asarray(list(a[0].values())) for a in dataset])\n",
    "dataset_y = np.asarray([a[1] for a in dataset])\n",
    "\n",
    "tsne.predict(dataset_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'empty_server_form_handler': 0.0, 'popup_window': 0.0, 'https': 0.0, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 0.0, 'is_popular': 0.5, 'long_url': 1.0, 'age_of_domain': 1, 'ip_in_url': 1}, True)\n",
      "({'empty_server_form_handler': 1.0, 'popup_window': 0.0, 'https': 0.5, 'request_from_other_domain': 0.5, 'anchor_from_other_domain': 0.0, 'is_popular': 0.5, 'long_url': 0.0, 'age_of_domain': 1, 'ip_in_url': 0}, True)\n",
      "({'empty_server_form_handler': 0.0, 'popup_window': 0.0, 'https': 1.0, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 0.5, 'is_popular': 0.5, 'long_url': 0.0, 'age_of_domain': 1, 'ip_in_url': 0}, True)\n",
      "({'empty_server_form_handler': 0.0, 'popup_window': 0.0, 'https': 1.0, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 0.0, 'is_popular': 1.0, 'long_url': 0.5, 'age_of_domain': 0, 'ip_in_url': 0}, True)\n",
      "({'empty_server_form_handler': 1.0, 'popup_window': 0.0, 'https': 0.5, 'request_from_other_domain': 1.0, 'anchor_from_other_domain': 0.0, 'is_popular': 0.5, 'long_url': 0.5, 'age_of_domain': 1, 'ip_in_url': 0}, False)\n",
      "({'empty_server_form_handler': 1.0, 'popup_window': 0.5, 'https': 1.0, 'request_from_other_domain': 1.0, 'anchor_from_other_domain': 0.5, 'is_popular': 0.5, 'long_url': 0.5, 'age_of_domain': 1, 'ip_in_url': 1}, False)\n",
      "({'empty_server_form_handler': 0.0, 'popup_window': 0.5, 'https': 0.0, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 1.0, 'is_popular': 1.0, 'long_url': 0.5, 'age_of_domain': 0, 'ip_in_url': 0}, True)\n",
      "({'empty_server_form_handler': 0.0, 'popup_window': 0.0, 'https': 0.5, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 0.0, 'is_popular': 1.0, 'long_url': 0.0, 'age_of_domain': 0, 'ip_in_url': 0}, True)\n",
      "({'empty_server_form_handler': 1.0, 'popup_window': 0.5, 'https': 1.0, 'request_from_other_domain': 1.0, 'anchor_from_other_domain': 1.0, 'is_popular': 0.0, 'long_url': 1.0, 'age_of_domain': 1, 'ip_in_url': 0}, False)\n",
      "({'empty_server_form_handler': 1.0, 'popup_window': 0.0, 'https': 0.5, 'request_from_other_domain': 0.0, 'anchor_from_other_domain': 1.0, 'is_popular': 0.5, 'long_url': 1.0, 'age_of_domain': 1, 'ip_in_url': 0}, True)\n"
     ]
    }
   ],
   "source": [
    "for a in datasets.Phishing().take(10):\n",
    "    print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
